{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"qGSAOCMlzDmD","executionInfo":{"status":"ok","timestamp":1710569690625,"user_tz":-480,"elapsed":720691,"user":{"displayName":"Ryan Ming","userId":"15132354585412009292"}},"outputId":"6054930c-f023-412a-cafa-280e3877066c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 106008565.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 66230559.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 33027021.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 15488234.77it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n","  warnings.warn(\"test_data has been renamed data\")\n","<ipython-input-1-5387040e5664>:24: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  test_x = Variable(torch.unsqueeze(test_data.test_data,dim  = 1),volatile = True).type(torch.FloatTensor)[:500]/255.\n","/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n","  warnings.warn(\"test_labels has been renamed targets\")\n","<ipython-input-1-5387040e5664>:71: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  output = F.softmax(out2)\n"]},{"output_type":"stream","name":"stdout","text":["========== 20 ===== ===== test accuracy is  0.24 ==========\n","========== 40 ===== ===== test accuracy is  0.438 ==========\n","========== 60 ===== ===== test accuracy is  0.524 ==========\n","========== 80 ===== ===== test accuracy is  0.598 ==========\n","========== 100 ===== ===== test accuracy is  0.658 ==========\n","========== 120 ===== ===== test accuracy is  0.708 ==========\n","========== 140 ===== ===== test accuracy is  0.732 ==========\n","========== 160 ===== ===== test accuracy is  0.778 ==========\n","========== 180 ===== ===== test accuracy is  0.798 ==========\n","========== 200 ===== ===== test accuracy is  0.816 ==========\n","========== 220 ===== ===== test accuracy is  0.786 ==========\n","========== 240 ===== ===== test accuracy is  0.852 ==========\n","========== 260 ===== ===== test accuracy is  0.852 ==========\n","========== 280 ===== ===== test accuracy is  0.858 ==========\n","========== 300 ===== ===== test accuracy is  0.864 ==========\n","========== 320 ===== ===== test accuracy is  0.868 ==========\n","========== 340 ===== ===== test accuracy is  0.88 ==========\n","========== 360 ===== ===== test accuracy is  0.872 ==========\n","========== 380 ===== ===== test accuracy is  0.886 ==========\n","========== 400 ===== ===== test accuracy is  0.894 ==========\n","========== 420 ===== ===== test accuracy is  0.884 ==========\n","========== 440 ===== ===== test accuracy is  0.886 ==========\n","========== 460 ===== ===== test accuracy is  0.896 ==========\n","========== 480 ===== ===== test accuracy is  0.896 ==========\n","========== 500 ===== ===== test accuracy is  0.902 ==========\n","========== 520 ===== ===== test accuracy is  0.914 ==========\n","========== 540 ===== ===== test accuracy is  0.912 ==========\n","========== 560 ===== ===== test accuracy is  0.922 ==========\n","========== 580 ===== ===== test accuracy is  0.912 ==========\n","========== 600 ===== ===== test accuracy is  0.914 ==========\n","========== 620 ===== ===== test accuracy is  0.908 ==========\n","========== 640 ===== ===== test accuracy is  0.914 ==========\n","========== 660 ===== ===== test accuracy is  0.926 ==========\n","========== 680 ===== ===== test accuracy is  0.92 ==========\n","========== 700 ===== ===== test accuracy is  0.912 ==========\n","========== 720 ===== ===== test accuracy is  0.926 ==========\n","========== 740 ===== ===== test accuracy is  0.934 ==========\n","========== 760 ===== ===== test accuracy is  0.926 ==========\n","========== 780 ===== ===== test accuracy is  0.93 ==========\n","========== 800 ===== ===== test accuracy is  0.932 ==========\n","========== 820 ===== ===== test accuracy is  0.936 ==========\n","========== 840 ===== ===== test accuracy is  0.936 ==========\n","========== 860 ===== ===== test accuracy is  0.938 ==========\n","========== 880 ===== ===== test accuracy is  0.934 ==========\n","========== 900 ===== ===== test accuracy is  0.946 ==========\n","========== 920 ===== ===== test accuracy is  0.946 ==========\n","========== 940 ===== ===== test accuracy is  0.936 ==========\n","========== 960 ===== ===== test accuracy is  0.934 ==========\n","========== 980 ===== ===== test accuracy is  0.936 ==========\n","========== 1000 ===== ===== test accuracy is  0.946 ==========\n","========== 1020 ===== ===== test accuracy is  0.952 ==========\n","========== 1040 ===== ===== test accuracy is  0.944 ==========\n","========== 1060 ===== ===== test accuracy is  0.948 ==========\n","========== 1080 ===== ===== test accuracy is  0.95 ==========\n","========== 1100 ===== ===== test accuracy is  0.942 ==========\n","========== 1120 ===== ===== test accuracy is  0.942 ==========\n","========== 1140 ===== ===== test accuracy is  0.958 ==========\n","========== 1160 ===== ===== test accuracy is  0.958 ==========\n","========== 1180 ===== ===== test accuracy is  0.954 ==========\n","========== 20 ===== ===== test accuracy is  0.956 ==========\n","========== 40 ===== ===== test accuracy is  0.956 ==========\n","========== 60 ===== ===== test accuracy is  0.95 ==========\n","========== 80 ===== ===== test accuracy is  0.958 ==========\n","========== 100 ===== ===== test accuracy is  0.94 ==========\n","========== 120 ===== ===== test accuracy is  0.954 ==========\n","========== 140 ===== ===== test accuracy is  0.962 ==========\n","========== 160 ===== ===== test accuracy is  0.95 ==========\n","========== 180 ===== ===== test accuracy is  0.954 ==========\n","========== 200 ===== ===== test accuracy is  0.964 ==========\n","========== 220 ===== ===== test accuracy is  0.954 ==========\n","========== 240 ===== ===== test accuracy is  0.962 ==========\n","========== 260 ===== ===== test accuracy is  0.956 ==========\n","========== 280 ===== ===== test accuracy is  0.968 ==========\n","========== 300 ===== ===== test accuracy is  0.96 ==========\n","========== 320 ===== ===== test accuracy is  0.964 ==========\n","========== 340 ===== ===== test accuracy is  0.954 ==========\n","========== 360 ===== ===== test accuracy is  0.956 ==========\n","========== 380 ===== ===== test accuracy is  0.948 ==========\n","========== 400 ===== ===== test accuracy is  0.962 ==========\n","========== 420 ===== ===== test accuracy is  0.954 ==========\n","========== 440 ===== ===== test accuracy is  0.95 ==========\n","========== 460 ===== ===== test accuracy is  0.97 ==========\n","========== 480 ===== ===== test accuracy is  0.96 ==========\n","========== 500 ===== ===== test accuracy is  0.96 ==========\n","========== 520 ===== ===== test accuracy is  0.964 ==========\n","========== 540 ===== ===== test accuracy is  0.962 ==========\n","========== 560 ===== ===== test accuracy is  0.956 ==========\n","========== 580 ===== ===== test accuracy is  0.958 ==========\n","========== 600 ===== ===== test accuracy is  0.966 ==========\n","========== 620 ===== ===== test accuracy is  0.96 ==========\n","========== 640 ===== ===== test accuracy is  0.97 ==========\n","========== 660 ===== ===== test accuracy is  0.958 ==========\n","========== 680 ===== ===== test accuracy is  0.964 ==========\n","========== 700 ===== ===== test accuracy is  0.966 ==========\n","========== 720 ===== ===== test accuracy is  0.96 ==========\n","========== 740 ===== ===== test accuracy is  0.95 ==========\n","========== 760 ===== ===== test accuracy is  0.962 ==========\n","========== 780 ===== ===== test accuracy is  0.966 ==========\n","========== 800 ===== ===== test accuracy is  0.968 ==========\n","========== 820 ===== ===== test accuracy is  0.962 ==========\n","========== 840 ===== ===== test accuracy is  0.976 ==========\n","========== 860 ===== ===== test accuracy is  0.956 ==========\n","========== 880 ===== ===== test accuracy is  0.956 ==========\n","========== 900 ===== ===== test accuracy is  0.964 ==========\n","========== 920 ===== ===== test accuracy is  0.964 ==========\n","========== 940 ===== ===== test accuracy is  0.962 ==========\n","========== 960 ===== ===== test accuracy is  0.972 ==========\n","========== 980 ===== ===== test accuracy is  0.978 ==========\n","========== 1000 ===== ===== test accuracy is  0.97 ==========\n","========== 1020 ===== ===== test accuracy is  0.966 ==========\n","========== 1040 ===== ===== test accuracy is  0.972 ==========\n","========== 1060 ===== ===== test accuracy is  0.956 ==========\n","========== 1080 ===== ===== test accuracy is  0.958 ==========\n","========== 1100 ===== ===== test accuracy is  0.964 ==========\n","========== 1120 ===== ===== test accuracy is  0.964 ==========\n","========== 1140 ===== ===== test accuracy is  0.962 ==========\n","========== 1160 ===== ===== test accuracy is  0.966 ==========\n","========== 1180 ===== ===== test accuracy is  0.978 ==========\n","========== 20 ===== ===== test accuracy is  0.976 ==========\n","========== 40 ===== ===== test accuracy is  0.97 ==========\n","========== 60 ===== ===== test accuracy is  0.968 ==========\n","========== 80 ===== ===== test accuracy is  0.97 ==========\n","========== 100 ===== ===== test accuracy is  0.968 ==========\n","========== 120 ===== ===== test accuracy is  0.968 ==========\n","========== 140 ===== ===== test accuracy is  0.974 ==========\n","========== 160 ===== ===== test accuracy is  0.962 ==========\n","========== 180 ===== ===== test accuracy is  0.968 ==========\n","========== 200 ===== ===== test accuracy is  0.976 ==========\n","========== 220 ===== ===== test accuracy is  0.964 ==========\n","========== 240 ===== ===== test accuracy is  0.97 ==========\n","========== 260 ===== ===== test accuracy is  0.968 ==========\n","========== 280 ===== ===== test accuracy is  0.974 ==========\n","========== 300 ===== ===== test accuracy is  0.974 ==========\n","========== 320 ===== ===== test accuracy is  0.966 ==========\n","========== 340 ===== ===== test accuracy is  0.964 ==========\n","========== 360 ===== ===== test accuracy is  0.968 ==========\n","========== 380 ===== ===== test accuracy is  0.972 ==========\n","========== 400 ===== ===== test accuracy is  0.968 ==========\n","========== 420 ===== ===== test accuracy is  0.97 ==========\n","========== 440 ===== ===== test accuracy is  0.972 ==========\n","========== 460 ===== ===== test accuracy is  0.966 ==========\n","========== 480 ===== ===== test accuracy is  0.974 ==========\n","========== 500 ===== ===== test accuracy is  0.972 ==========\n","========== 520 ===== ===== test accuracy is  0.974 ==========\n","========== 540 ===== ===== test accuracy is  0.97 ==========\n","========== 560 ===== ===== test accuracy is  0.978 ==========\n","========== 580 ===== ===== test accuracy is  0.974 ==========\n","========== 600 ===== ===== test accuracy is  0.97 ==========\n","========== 620 ===== ===== test accuracy is  0.968 ==========\n","========== 640 ===== ===== test accuracy is  0.964 ==========\n","========== 660 ===== ===== test accuracy is  0.972 ==========\n","========== 680 ===== ===== test accuracy is  0.976 ==========\n","========== 700 ===== ===== test accuracy is  0.974 ==========\n","========== 720 ===== ===== test accuracy is  0.972 ==========\n","========== 740 ===== ===== test accuracy is  0.966 ==========\n","========== 760 ===== ===== test accuracy is  0.972 ==========\n","========== 780 ===== ===== test accuracy is  0.974 ==========\n","========== 800 ===== ===== test accuracy is  0.976 ==========\n","========== 820 ===== ===== test accuracy is  0.98 ==========\n","========== 840 ===== ===== test accuracy is  0.97 ==========\n","========== 860 ===== ===== test accuracy is  0.978 ==========\n","========== 880 ===== ===== test accuracy is  0.978 ==========\n","========== 900 ===== ===== test accuracy is  0.978 ==========\n","========== 920 ===== ===== test accuracy is  0.982 ==========\n","========== 940 ===== ===== test accuracy is  0.982 ==========\n","========== 960 ===== ===== test accuracy is  0.966 ==========\n","========== 980 ===== ===== test accuracy is  0.976 ==========\n","========== 1000 ===== ===== test accuracy is  0.98 ==========\n","========== 1020 ===== ===== test accuracy is  0.98 ==========\n","========== 1040 ===== ===== test accuracy is  0.968 ==========\n","========== 1060 ===== ===== test accuracy is  0.98 ==========\n","========== 1080 ===== ===== test accuracy is  0.982 ==========\n","========== 1100 ===== ===== test accuracy is  0.97 ==========\n","========== 1120 ===== ===== test accuracy is  0.974 ==========\n","========== 1140 ===== ===== test accuracy is  0.972 ==========\n","========== 1160 ===== ===== test accuracy is  0.978 ==========\n","========== 1180 ===== ===== test accuracy is  0.974 ==========\n"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.utils.data as Data\n","import torchvision\n","import torch.nn.functional as F\n","import numpy as np\n","learning_rate = 1e-4\n","keep_prob_rate = 0.7 #\n","max_epoch = 3\n","BATCH_SIZE = 50\n","\n","DOWNLOAD_MNIST = False\n","if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n","    # not mnist dir or mnist is empyt dir\n","    DOWNLOAD_MNIST = True\n","\n","\n","train_data = torchvision.datasets.MNIST(root='./mnist/',train=True, transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST,)\n","train_loader = Data.DataLoader(dataset = train_data ,batch_size= BATCH_SIZE ,shuffle= True)\n","\n","test_data = torchvision.datasets.MNIST(root = './mnist/',train = False)\n","test_x = Variable(torch.unsqueeze(test_data.test_data,dim  = 1),volatile = True).type(torch.FloatTensor)[:500]/255.\n","test_y = test_data.test_labels[:500].numpy()\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d( # ???\n","                # patch 7 * 7 ; 1  in channels ; 32 out channels ; ; stride is 1\n","                # padding style is same(that means the convolution opration's input and output have the same size)\n","                in_channels=      1,\n","                out_channels=     32,\n","                kernel_size=      7,\n","                stride=           1,\n","                padding=          3,\n","            ),\n","            nn.ReLU(),        # activation function\n","            nn.MaxPool2d(2),  # pooling operation\n","        )\n","        self.conv2 = nn.Sequential( # ???\n","            # line 1 : convolution function, patch 5*5 , 32 in channels ;64 out channels; padding style is same; stride is 1\n","            # line 2 : choosing your activation function\n","            # line 3 : pooling operation function.\n","            nn.Conv2d(\n","                in_channels=32,\n","                out_channels=64,\n","                kernel_size=5,\n","                stride=1,\n","                padding=2\n","            ),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.out1 = nn.Linear( 7*7*64 , 1024 , bias= True)   # full connection layer one\n","        self.dropout = nn.Dropout(keep_prob_rate)\n","        self.out2 = nn.Linear(1024,10,bias=True)\n","\n","\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = x.view(x.size(0), -1)  # flatten the output of conv2 to (batch_size ,32 * 7 * 7)    # ???\n","        out1 = self.out1(x)\n","        out1 = F.relu(out1)\n","        out1 = self.dropout(out1)\n","        out2 = self.out2(out1)\n","        output = F.softmax(out2)\n","        return output\n","\n","\n","def test(cnn):\n","    global prediction\n","    y_pre = cnn(test_x)\n","    _,pre_index= torch.max(y_pre,1)\n","    pre_index= pre_index.view(-1)\n","    prediction = pre_index.data.numpy()\n","    correct  = np.sum(prediction == test_y)\n","    return correct / 500.0\n","\n","\n","def train(cnn):\n","    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate )\n","    loss_func = nn.CrossEntropyLoss()\n","    for epoch in range(max_epoch):\n","        for step, (x_, y_) in enumerate(train_loader):\n","            x ,y= Variable(x_),Variable(y_)\n","            output = cnn(x)\n","            loss = loss_func(output,y)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            if step != 0 and step % 20 ==0:\n","                print(\"=\" * 10,step,\"=\"*5,\"=\"*5, \"test accuracy is \",test(cnn) ,\"=\" * 10 )\n","\n","if __name__ == '__main__':\n","    cnn = CNN()\n","    train(cnn)\n","\n","\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}